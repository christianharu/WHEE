{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = 'non_hri_data_cues.csv'\n",
    "current_folder = os.getcwd()\n",
    "\n",
    "database_path = os.path.join(current_folder, 'processed_datasets',database_name)\n",
    "\n",
    "database = pd.read_csv(database_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random 10% of the data for test set\n",
    "test_set = database.sample(frac=0.1, random_state=42)\n",
    "remaining_data = database.drop(test_set.index)\n",
    "\n",
    "# split val and train\n",
    "val_set = remaining_data.sample(frac=0.1, random_state=42)\n",
    "train_set = remaining_data.drop(val_set.index)\n",
    "\n",
    "\n",
    "test_set_path = os.path.join(current_folder, 'processed_datasets','non_hri_data_test.csv')\n",
    "val_set_path = os.path.join(current_folder, 'processed_datasets','non_hri_data_val.csv')\n",
    "train_set_path = os.path.join(current_folder, 'processed_datasets','non_hri_data_train.csv')\n",
    "\n",
    "test_set.to_csv(test_set_path, index=False)\n",
    "val_set.to_csv(val_set_path, index=False)\n",
    "train_set.to_csv(train_set_path, index=False)\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total samples per class\n",
    "total_samples = len(database)\n",
    "samples_per_label = int(0.1 * total_samples / 3)\n",
    "\n",
    "df_test_label_0 = database[database['label'] == 0].sample(n=samples_per_label, random_state=42)\n",
    "df_test_label_1 = database[database['label'] == 1].sample(n=samples_per_label, random_state=42)\n",
    "df_test_label_2 = database[database['label'] == 2].sample(n=samples_per_label, random_state=42)\n",
    "\n",
    "# combine the samples\n",
    "balanced_test = pd.concat([df_test_label_0, df_test_label_1, df_test_label_2])\n",
    "\n",
    "# shuffle the data\n",
    "balanced_test = balanced_test.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# remove the samples from the database\n",
    "database = database.drop(df_test_label_0.index)\n",
    "database = database.drop(df_test_label_1.index)\n",
    "database = database.drop(df_test_label_2.index)\n",
    "\n",
    "# split val and train sets\n",
    "df_val_label_0 = database[database['label'] == 0].sample(n=samples_per_label, random_state=42)\n",
    "df_val_label_1 = database[database['label'] == 1].sample(n=samples_per_label, random_state=42)\n",
    "df_val_label_2 = database[database['label'] == 2].sample(n=samples_per_label, random_state=42)\n",
    "\n",
    "val_set = pd.concat([df_val_label_0, df_val_label_1, df_val_label_2])\n",
    "\n",
    "# shuffle the data\n",
    "val_set = val_set.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# remove the samples from the database\n",
    "database = database.drop(df_val_label_0.index)\n",
    "database = database.drop(df_val_label_1.index)\n",
    "database = database.drop(df_val_label_2.index)\n",
    "\n",
    "train_set = database\n",
    "\n",
    "\n",
    "# save the balanced test set\n",
    "balanced_test_path = os.path.join(current_folder, 'processed_datasets','non_hri_data_balanced_test.csv')\n",
    "balanced_test.to_csv(balanced_test_path, index=False)\n",
    "\n",
    "# save the val and train sets\n",
    "val_set_path = os.path.join(current_folder, 'processed_datasets','non_hri_data_balanced_val.csv')\n",
    "val_set.to_csv(val_set_path, index=False)\n",
    "\n",
    "train_set_path = os.path.join(current_folder, 'processed_datasets','non_hri_data_balanced_train.csv')\n",
    "train_set.to_csv(train_set_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "empathy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
